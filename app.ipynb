{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "class ImageClusteringAlgorithm:\n",
    "    def __init__(self):\n",
    "        self.facenet_model = InceptionResnetV1(pretrained=\"vggface2\").eval()\n",
    "        self.resnet_model = models.resnet18(pretrained=True).eval()\n",
    "        self.caption_pipeline = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "        self.language_model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.language_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        # Define the transformation layers to make the shapes of the output of facenet, resnet, and language models the same\n",
    "        self.face_transform = torch.nn.Linear(512, 1000)\n",
    "        self.caption_transform = torch.nn.Linear(768, 1000)        \n",
    "\n",
    "    def compute_features(self, image_directory):\n",
    "        self.image_directory = os.path.expanduser(image_directory)\n",
    "        file_extensions = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tiff\", \"*tif\")\n",
    "        self.image_paths = []\n",
    "        for extension in tqdm(file_extensions, \"Loading image paths\"):\n",
    "            self.image_paths.extend(glob.glob(os.path.join(self.image_directory, extension)))\n",
    "        features = []\n",
    "        for image_path in tqdm(self.image_paths, desc=\"Computing features\"):\n",
    "            feature = self._generate_image_features(image_path)\n",
    "            features.append(feature)\n",
    "        self.features = np.vstack(features)\n",
    "\n",
    "    def compute_clusters(self, num_clusters):\n",
    "        self.num_clusters = num_clusters\n",
    "        print(f\"Clustering images into {self.num_clusters} clusters...\")\n",
    "        kmeans = KMeans(n_clusters=self.num_clusters, random_state=42)\n",
    "        self.labels = kmeans.fit_predict(self.features)\n",
    "        print(\"Computing silhouette score...\")\n",
    "        silhouette_avg = silhouette_score(self.features, self.labels)\n",
    "        print(f\"Silhouette score: {silhouette_avg:.4f}\")\n",
    "        self.clusters = [[] for _ in range(self.labels.max() + 1)]\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            self.clusters[label].append(self.image_paths[idx])\n",
    "\n",
    "    def save_clustered_images(self, output_directory):\n",
    "        output_directory = os.path.expanduser(output_directory)\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        for cluster_id in range(self.num_clusters):\n",
    "            cluster_dir = os.path.join(output_directory, f\"cluster_{cluster_id}\")\n",
    "            os.makedirs(cluster_dir, exist_ok=True)\n",
    "            for image_path in self.clusters[cluster_id]:\n",
    "                new_filename = os.path.join(cluster_dir, os.path.basename(image_path))\n",
    "                shutil.copyfile(image_path, new_filename)\n",
    "\n",
    "    def _generate_image_features(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
    "        image_tensor = transform(image).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            resnet_features = self.resnet_model(image_tensor)\n",
    "            face_features = self.face_transform(self.facenet_model(image_tensor))\n",
    "            caption_features = self.caption_transform(self._generate_caption(image_path))\n",
    "        features = np.concatenate((face_features.detach().numpy(), resnet_features.detach().numpy(), caption_features.detach().numpy()))\n",
    "        return features\n",
    "\n",
    "    def _generate_caption(self, image_path):\n",
    "        caption = self.caption_pipeline(image_path)[0][\"generated_text\"]\n",
    "        tokens = self.language_tokenizer.encode(caption, return_tensors=\"pt\")\n",
    "        vector = self.language_model(tokens).last_hidden_state.mean(dim=1)\n",
    "        return vector\n",
    "    \n",
    "    def save_features(self, file_name):\n",
    "        data = { \"features\": self.features, \"image_paths\": self.image_paths, \"image_directory\": self.image_directory }\n",
    "        with open(file_name, \"wb\") as file: \n",
    "            pickle.dump(data, file)\n",
    "    \n",
    "    def load_features(self, file_name):\n",
    "        with open(file_name, \"b\") as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        ica = ImageClusteringAlgorithm()\n",
    "        ica.features = data[\"features\"]\n",
    "        ica.image_paths = data[\"image_paths\"]\n",
    "        ica.image_directory = data[\"image_directory\"]\n",
    "\n",
    "    def save_clusters(self, file_name):\n",
    "        data = { \"num_clusters\": self.num_clusters, \"clusters\": self.clusters }\n",
    "        with open(file_name, \"wb\") as file: \n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_features(self, file_name):\n",
    "        with open(file_name, \"b\") as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        ica = ImageClusteringAlgorithm()\n",
    "        ica.num_clusters = data[\"clusters\"]\n",
    "        ica.clusters = data[\"clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderschiffhauer/.local/share/virtualenvs/clustering-NSSxPA_6/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/alexanderschiffhauer/.local/share/virtualenvs/clustering-NSSxPA_6/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Loading image paths: 100%|██████████| 6/6 [00:00<00:00, 106.77it/s]\n",
      "Computing features:   0%|          | 0/8617 [00:00<?, ?it/s]/Users/alexanderschiffhauer/.local/share/virtualenvs/clustering-NSSxPA_6/lib/python3.11/site-packages/transformers/generation/utils.py:1313: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "Computing features:   1%|          | 75/8617 [02:14<4:21:37,  1.84s/it]"
     ]
    }
   ],
   "source": [
    "ica = ImageClusteringAlgorithm()\n",
    "image_directory = \"~/Downloads/JPGs\"\n",
    "features_file = \"~/Downloads/JPGs/ImageClusteringAlgorithmFeatures.pkl\"\n",
    "clusters_file = \"~/Downloads/JPGs/ImageClusteringAlgorithmClusters.pkl\"\n",
    "if not os.path.exists(features_file):\n",
    "    ica.compute_features(image_directory)\n",
    "    ica.save_features(features_file)\n",
    "else:\n",
    "    ica.load_features(features_file)\n",
    "if not os.path.exists(clusters_file):\n",
    "    num_clusters = 50\n",
    "    ica.compute_clusters(num_clusters)\n",
    "    ica.save_clusters(clusters_file)\n",
    "else:\n",
    "    ica.load_clusters(clusters_file)\n",
    "ica.save_clustered_images(\"~/Downloads/ClusteredJPGs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-NSSxPA_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
