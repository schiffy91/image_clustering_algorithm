{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from transformers import pipeline, AutoTokenizer, AutoModel\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "version = \"0.1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "class ImageClusteringAlgorithm:\n",
    "    def __init__(self):\n",
    "        self.facenet_model = InceptionResnetV1(pretrained=\"vggface2\").eval().to(device)\n",
    "        self.resnet_model = models.resnet18(pretrained=True).eval().to(device)\n",
    "        self.caption_pipeline = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\", device=device)\n",
    "        self.language_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
    "        self.language_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "        # Define the transformation layers to make the shapes of the output of facenet, resnet, and language models the same\n",
    "        self.face_transform = torch.nn.Linear(512, 1000).to(device)\n",
    "        self.caption_transform = torch.nn.Linear(768, 1000).to(device)\n",
    "\n",
    "    def compute_features(self, image_directory, use_facenet=True, use_resnet=True, use_caption=True):\n",
    "        self.image_directory = os.path.expanduser(image_directory)\n",
    "        file_extensions = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.tiff\", \"*.tif\")\n",
    "        self.image_paths = []\n",
    "        for extension in tqdm(file_extensions, \"Loading image paths...\"):\n",
    "            self.image_paths.extend(glob.glob(os.path.join(self.image_directory, extension)))\n",
    "        features = []\n",
    "        for image_path in tqdm(self.image_paths, desc=\"Computing features...\"):\n",
    "            feature = self._generate_image_features(image_path, use_facenet, use_resnet, use_caption)\n",
    "            features.append(feature)\n",
    "        self.features = np.vstack(features)\n",
    "\n",
    "    def compute_clusters(self, num_clusters, use_facenet=True, use_resnet=True, use_caption=True):\n",
    "        self.num_clusters = num_clusters\n",
    "        selected_features = self._select_features(self.features, use_facenet, use_resnet, use_caption)\n",
    "        print(f\"Clustering images into {self.num_clusters} clusters...\")\n",
    "        kmeans = KMeans(n_clusters=self.num_clusters, random_state=42)\n",
    "        self.labels = kmeans.fit_predict(selected_features)\n",
    "        print(\"Computing silhouette score...\")\n",
    "        silhouette_avg = silhouette_score(selected_features, self.labels)\n",
    "        print(f\"Silhouette score: {silhouette_avg:.4f}\")\n",
    "        self.clusters = [[] for _ in range(self.labels.max() + 1)]\n",
    "        for idx, label in enumerate(self.labels):\n",
    "            self.clusters[label].append(self.image_paths[idx])\n",
    "\n",
    "    def save_clustered_images(self, output_directory):\n",
    "        output_directory = os.path.expanduser(output_directory)\n",
    "        os.makedirs(output_directory, exist_ok=True)\n",
    "        for cluster_id in tqdm(range(self.num_clusters), \"Saving clusters...\"):\n",
    "            cluster_dir = os.path.join(output_directory, f\"cluster_{cluster_id}\")\n",
    "            os.makedirs(cluster_dir, exist_ok=True)\n",
    "            for image_path in self.clusters[cluster_id]:\n",
    "                new_filename = os.path.join(cluster_dir, os.path.basename(image_path))\n",
    "                shutil.copyfile(image_path, new_filename)\n",
    "\n",
    "    def _generate_image_features(self, image_path, use_facenet, use_resnet, use_caption):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        transform = transforms.Compose([transforms.Resize((512, 512)), transforms.ToTensor()])\n",
    "        image_tensor = transform(image).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            resnet_features = self.resnet_model(image_tensor)\n",
    "            face_features = self.face_transform(self.facenet_model(image_tensor))\n",
    "            caption_features = self.caption_transform(self._generate_caption(image_path))\n",
    "        features = np.concatenate((face_features.cpu().detach().numpy(), resnet_features.cpu().detach().numpy(), caption_features.cpu().detach().numpy()), axis=1)\n",
    "        selected_features = self._select_features(features, use_facenet, use_resnet, use_caption)\n",
    "        return selected_features\n",
    "\n",
    "    def _generate_caption(self, image_path):\n",
    "        caption = self.caption_pipeline(image_path)[0][\"generated_text\"]\n",
    "        tokens = self.language_tokenizer.encode(caption, return_tensors=\"pt\").to(device)\n",
    "        vector = self.language_model(tokens).last_hidden_state.mean(dim=1)\n",
    "        return vector\n",
    "    \n",
    "    def _select_features(self, features, use_facenet=True, use_resnet=True, use_caption=True):\n",
    "        feature_sizes = [self.face_transform.out_features, self.resnet_model.fc.out_features, self.caption_transform.out_features]\n",
    "        feature_start_indices = np.cumsum([0] + feature_sizes)\n",
    "        selected_features = []\n",
    "        if use_facenet:\n",
    "            selected_features.append(features[:, feature_start_indices[0]:feature_start_indices[1]])\n",
    "        if use_resnet:\n",
    "            selected_features.append(features[:, feature_start_indices[1]:feature_start_indices[2]])\n",
    "        if use_caption:\n",
    "            selected_features.append(features[:, feature_start_indices[2]:])\n",
    "        return np.concatenate(selected_features, axis=1)\n",
    "    \n",
    "    def save_features(self, file_name):\n",
    "        file_name = os.path.expanduser(file_name)\n",
    "        data = { \"features\": self.features, \"image_paths\": self.image_paths, \"image_directory\": self.image_directory, \"version\": version }\n",
    "        with open(file_name, \"wb\") as file: \n",
    "            pickle.dump(data, file)\n",
    "    \n",
    "    def load_features(self, file_name):\n",
    "        file_name = os.path.expanduser(file_name)\n",
    "        with open(file_name, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.features = data[\"features\"]\n",
    "        self.image_paths = data[\"image_paths\"]\n",
    "        self.image_directory = data[\"image_directory\"]\n",
    "\n",
    "    def save_clusters(self, file_name):\n",
    "        file_name = os.path.expanduser(file_name)\n",
    "        data = { \"num_clusters\": self.num_clusters, \"clusters\": self.clusters, \"version\": version }\n",
    "        with open(file_name, \"wb\") as file: \n",
    "            pickle.dump(data, file)\n",
    "\n",
    "    def load_clusters(self, file_name):\n",
    "        with open(file_name, \"rb\") as file:\n",
    "            data = pickle.load(file)\n",
    "        self.num_clusters = data[\"clusters\"]\n",
    "        self.clusters = data[\"clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ImageClusteringAlgorithm()\n",
    "image_directory = os.path.expanduser(\"~/Downloads/JPGs\")\n",
    "features_file = os.path.expanduser(\"~/Downloads/JPGs/FaceResCapF_v0.1.pkl\")\n",
    "clusters_file = os.path.expanduser(\"~/Downloads/JPGs/FaceResCapC_v0.1.pkl\")\n",
    "if not os.path.exists(features_file):\n",
    "    ica.compute_features(image_directory)\n",
    "    ica.save_features(features_file)\n",
    "else:\n",
    "    ica.load_features(features_file)\n",
    "if not os.path.exists(clusters_file):\n",
    "    num_clusters = 50\n",
    "    ica.compute_clusters(num_clusters)\n",
    "    ica.save_clusters(clusters_file)\n",
    "else:\n",
    "    ica.load_clusters(clusters_file)\n",
    "ica.save_clustered_images(\"~/Downloads/ClusteredJPGs2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica = ImageClusteringAlgorithm()\n",
    "features_file = os.path.expanduser(\"~/Downloads/JPGs/FaceResCapF_v0.1.pkl\")\n",
    "clusters_file = os.path.expanduser(\"~/Downloads/JPGs/FaceResCapC_v0.1.pkl\")\n",
    "ica.load_features(features_file)\n",
    "num_clusters = 50\n",
    "ica.compute_clusters(num_clusters)\n",
    "ica.load_features(features_file)\n",
    "ica.compute_clusters(num_clusters, use_facenet=False)\n",
    "ica.load_features(features_file)\n",
    "ica.compute_clusters(num_clusters, use_resnet=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clustering-NSSxPA_6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
